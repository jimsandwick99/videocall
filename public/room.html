<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">
    <title>Professional Interview Room</title>
    <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='80' font-size='80'>üé•</text></svg>">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        :root {
            --primary-gradient: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            --secondary-gradient: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            --dark-bg: #0a0e27;
            --card-bg: rgba(17, 25, 40, 0.75);
            --glass-bg: rgba(255, 255, 255, 0.05);
            --glass-border: rgba(255, 255, 255, 0.1);
            --text-primary: #ffffff;
            --text-secondary: #a8b2d1;
            --success: #10b981;
            --warning: #f59e0b;
            --danger: #ef4444;
            --muted: #6b7280;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background: var(--dark-bg);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            position: relative;
            overflow: hidden;
        }
        
        /* Animated background */
        body::before {
            content: '';
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: radial-gradient(circle at 20% 50%, rgba(102, 126, 234, 0.1) 0%, transparent 50%),
                        radial-gradient(circle at 80% 80%, rgba(118, 75, 162, 0.1) 0%, transparent 50%),
                        radial-gradient(circle at 40% 20%, rgba(240, 147, 251, 0.05) 0%, transparent 50%);
            pointer-events: none;
            animation: float 20s ease-in-out infinite;
        }
        
        @keyframes float {
            0%, 100% { transform: translate(0, 0) rotate(0deg); }
            33% { transform: translate(-20px, -20px) rotate(1deg); }
            66% { transform: translate(20px, -10px) rotate(-1deg); }
        }
        
        /* Header */
        .header {
            background: var(--glass-bg);
            backdrop-filter: blur(10px);
            border-bottom: 1px solid var(--glass-border);
            padding: 1rem 2rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
            z-index: 100;
        }
        
        .room-info {
            display: flex;
            align-items: center;
            gap: 1rem;
        }
        
        .room-badge {
            background: var(--primary-gradient);
            padding: 0.5rem 1rem;
            border-radius: 20px;
            font-size: 0.875rem;
            font-weight: 600;
            color: white;
            letter-spacing: 0.5px;
        }
        
        .connection-status {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: var(--glass-bg);
            border: 1px solid var(--glass-border);
            border-radius: 20px;
            font-size: 0.875rem;
            color: var(--text-secondary);
        }
        
        .status-dot {
            width: 8px;
            height: 8px;
            border-radius: 50%;
            background: var(--muted);
            animation: pulse 2s ease-in-out infinite;
        }
        
        .status-dot.connected {
            background: var(--success);
        }
        
        @keyframes pulse {
            0%, 100% { opacity: 1; transform: scale(1); }
            50% { opacity: 0.6; transform: scale(1.2); }
        }
        
        /* Main video container */
        .main-container {
            flex: 1;
            display: flex;
            padding: 2rem;
            gap: 2rem;
            max-height: calc(100vh - 180px);
        }
        
        /* Video grid */
        .video-grid {
            flex: 1;
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 1.5rem;
            max-width: 1400px;
            margin: 0 auto;
            width: 100%;
        }
        
        .video-card {
            position: relative;
            background: var(--card-bg);
            border-radius: 20px;
            overflow: hidden;
            border: 1px solid var(--glass-border);
            backdrop-filter: blur(10px);
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
            display: flex;
            align-items: center;
            justify-content: center;
            aspect-ratio: 16/9;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }
        
        .video-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 12px 40px rgba(0, 0, 0, 0.4);
        }
        
        .video-card.speaking {
            border-color: var(--success);
            box-shadow: 0 0 30px rgba(16, 185, 129, 0.3);
        }
        
        video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            display: block;
            background: #000;
        }
        
        .video-overlay {
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            padding: 1rem;
            background: linear-gradient(180deg, rgba(0,0,0,0.7) 0%, transparent 100%);
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
        }
        
        .participant-info {
            display: flex;
            align-items: center;
            gap: 0.75rem;
        }
        
        .participant-avatar {
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: var(--primary-gradient);
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            color: white;
            font-size: 1.2rem;
        }
        
        .participant-details {
            display: flex;
            flex-direction: column;
        }
        
        .participant-name {
            color: white;
            font-weight: 600;
            font-size: 0.95rem;
        }
        
        .participant-role {
            color: var(--text-secondary);
            font-size: 0.75rem;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }
        
        .audio-indicator {
            padding: 0.25rem 0.5rem;
            background: var(--glass-bg);
            border-radius: 10px;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .audio-bars {
            display: flex;
            gap: 2px;
            height: 16px;
            align-items: flex-end;
        }
        
        .audio-bar {
            width: 3px;
            background: var(--success);
            border-radius: 2px;
            transition: height 0.1s ease;
        }
        
        .audio-bar:nth-child(1) { height: 40%; animation: audioWave 0.5s ease-in-out infinite; }
        .audio-bar:nth-child(2) { height: 60%; animation: audioWave 0.5s ease-in-out infinite 0.1s; }
        .audio-bar:nth-child(3) { height: 50%; animation: audioWave 0.5s ease-in-out infinite 0.2s; }
        .audio-bar:nth-child(4) { height: 70%; animation: audioWave 0.5s ease-in-out infinite 0.3s; }
        
        @keyframes audioWave {
            0%, 100% { height: 40%; }
            50% { height: 100%; }
        }
        
        .muted-indicator {
            color: var(--danger);
            font-size: 1.2rem;
        }
        
        .video-placeholder {
            position: absolute;
            inset: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            background: radial-gradient(circle at center, var(--glass-bg) 0%, transparent 70%);
        }
        
        .placeholder-icon {
            font-size: 4rem;
            margin-bottom: 1rem;
            opacity: 0.3;
        }
        
        .placeholder-text {
            color: var(--text-secondary);
            font-size: 1rem;
        }
        
        /* Control bar */
        .control-bar {
            background: var(--glass-bg);
            backdrop-filter: blur(20px);
            border-top: 1px solid var(--glass-border);
            padding: 1.5rem;
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 1rem;
            position: relative;
            z-index: 100;
            flex-wrap: wrap;
            min-height: 90px;
        }
        
        .control-group {
            display: flex;
            gap: 0.75rem;
            padding: 0 1rem;
            border-right: 1px solid var(--glass-border);
            flex-shrink: 0;
        }
        
        .control-group:last-child {
            border-right: none;
        }
        
        .control-btn {
            position: relative;
            width: 50px;
            height: 50px;
            border: none;
            border-radius: 50%;
            background: var(--glass-bg);
            border: 1px solid var(--glass-border);
            color: var(--text-primary);
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.3rem;
            transition: all 0.3s ease;
            overflow: hidden;
        }
        
        .control-btn::before {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            width: 0;
            height: 0;
            border-radius: 50%;
            background: var(--primary-gradient);
            transform: translate(-50%, -50%);
            transition: width 0.3s ease, height 0.3s ease;
            z-index: -1;
        }
        
        .control-btn:hover::before {
            width: 100%;
            height: 100%;
        }
        
        .control-btn:hover {
            transform: translateY(-2px);
            border-color: transparent;
            box-shadow: 0 5px 20px rgba(102, 126, 234, 0.4);
        }
        
        .control-btn.active {
            background: var(--primary-gradient);
            border-color: transparent;
        }
        
        .control-btn.muted {
            background: var(--danger);
            border-color: transparent;
        }
        
        .control-btn.recording {
            animation: recordPulse 1.5s ease-in-out infinite;
            background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
        }
        
        @keyframes recordPulse {
            0%, 100% { 
                box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7);
                transform: scale(1);
            }
            50% { 
                box-shadow: 0 0 0 10px rgba(239, 68, 68, 0);
                transform: scale(1.05);
            }
        }
        
        .control-label {
            position: absolute;
            bottom: -25px;
            left: 50%;
            transform: translateX(-50%);
            font-size: 0.7rem;
            color: var(--text-secondary);
            white-space: nowrap;
            opacity: 0;
            transition: opacity 0.3s ease;
        }
        
        .control-btn:hover .control-label {
            opacity: 1;
        }
        
        .end-call-btn {
            background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
            width: 60px;
            border-radius: 30px;
        }
        
        .recording-indicator {
            position: absolute;
            top: 2rem;
            left: 50%;
            transform: translateX(-50%);
            background: var(--danger);
            color: white;
            padding: 0.5rem 1rem;
            border-radius: 20px;
            display: none;
            align-items: center;
            gap: 0.5rem;
            font-size: 0.875rem;
            font-weight: 600;
            animation: slideDown 0.3s ease;
        }
        
        .recording-indicator.active {
            display: flex;
        }
        
        @keyframes slideDown {
            from { transform: translateX(-50%) translateY(-20px); opacity: 0; }
            to { transform: translateX(-50%) translateY(0); opacity: 1; }
        }
        
        .recording-dot {
            width: 8px;
            height: 8px;
            background: white;
            border-radius: 50%;
            animation: recordBlink 1s ease-in-out infinite;
        }
        
        @keyframes recordBlink {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.3; }
        }
        
        /* Timer */
        .timer {
            position: absolute;
            top: 2rem;
            right: 2rem;
            background: var(--glass-bg);
            backdrop-filter: blur(10px);
            border: 1px solid var(--glass-border);
            padding: 0.75rem 1.5rem;
            border-radius: 15px;
            font-variant-numeric: tabular-nums;
            font-weight: 600;
            color: var(--text-primary);
            display: none;
        }
        
        .timer.active {
            display: block;
        }
        
        /* Mobile-specific styles */
        @media (max-width: 768px) {
            body {
                position: fixed;
                width: 100%;
                height: 100vh;
                height: 100dvh; /* Dynamic viewport height for mobile */
                overflow: hidden;
                padding: env(safe-area-inset-top) env(safe-area-inset-right) env(safe-area-inset-bottom) env(safe-area-inset-left);
            }
            
            .main-container {
                position: fixed;
                top: 60px;
                left: 0;
                right: 0;
                bottom: 70px;
                padding: 0;
                max-height: none;
                height: calc(100vh - 130px);
                overflow: hidden;
            }
            
            .video-grid {
                grid-template-columns: 1fr;
                gap: 0;
                height: 100%;
                position: relative;
            }
            
            /* Smaller local video (self-view) on mobile */
            .video-card:first-child {
                position: absolute;
                top: 10px;
                right: 10px;
                width: 90px;
                height: 120px;
                z-index: 85;
                aspect-ratio: unset;
                border-radius: 12px;
                box-shadow: 0 4px 12px rgba(0, 0, 0, 0.5);
            }
            
            /* Hide overlay info for small self-view */
            .video-card:first-child .video-overlay {
                display: none;
            }
            
            /* Main remote video takes full space */
            .video-card:last-child {
                position: absolute;
                top: 0;
                left: 0;
                width: 100%;
                height: 100%;
                aspect-ratio: unset;
                border-radius: 0;
            }
            
            .header {
                position: fixed;
                top: 0;
                left: 0;
                right: 0;
                height: 60px;
                padding: 0.75rem 1rem;
                font-size: 0.85rem;
                z-index: 100;
            }
            
            .room-badge {
                padding: 0.35rem 0.75rem;
                font-size: 0.75rem;
            }
            
            .connection-status {
                padding: 0.35rem 0.75rem;
                font-size: 0.75rem;
            }
            
            .control-bar {
                position: fixed;
                bottom: 0;
                bottom: env(safe-area-inset-bottom);
                left: 0;
                right: 0;
                height: 70px;
                padding: 0.75rem;
                padding-bottom: calc(0.75rem + env(safe-area-inset-bottom));
                gap: 0.5rem;
                background: rgba(10, 14, 39, 0.98);
                z-index: 100;
                display: flex;
                justify-content: center;
                align-items: center;
                border-top: 1px solid rgba(255, 255, 255, 0.1);
            }
            
            .control-btn {
                width: 42px;
                height: 42px;
                font-size: 1rem;
            }
            
            .control-group {
                gap: 0.5rem;
                padding: 0 0.5rem;
            }
            
            .control-label {
                display: none;
            }
            
            .end-call-btn {
                width: 50px;
            }
            
            .participant-info {
                gap: 0.5rem;
            }
            
            .participant-avatar {
                width: 30px;
                height: 30px;
                font-size: 1rem;
            }
            
            .participant-name {
                font-size: 0.85rem;
            }
            
            .participant-role {
                font-size: 0.7rem;
            }
            
            /* Hide recording controls on mobile for non-interviewers */
            #recordingControls {
                display: none !important;
            }
            
            /* Compact timer - position above control bar */
            .timer {
                position: fixed;
                top: auto;
                bottom: 75px;
                right: 10px;
                padding: 0.5rem 1rem;
                font-size: 0.85rem;
                border-radius: 20px;
                z-index: 99;
            }
            
            /* Recording indicator positioning */
            .recording-indicator {
                position: fixed;
                top: 65px;
                left: 50%;
                transform: translateX(-50%);
                z-index: 99;
            }
            
            /* Ensure video doesn't go under controls */
            video {
                object-fit: contain;
            }
        }
        
        /* Small mobile devices */
        @media (max-width: 480px) {
            .video-card:first-child {
                width: 80px;
                height: 110px;
                top: 5px;
                right: 5px;
            }
            
            .main-container {
                top: 50px;
                bottom: 65px;
                height: calc(100vh - 115px);
            }
            
            .header {
                height: 50px;
                padding: 0.5rem;
            }
            
            .control-bar {
                height: 65px;
                padding: 0.5rem;
            }
            
            .control-btn {
                width: 40px;
                height: 40px;
                font-size: 0.95rem;
            }
            
            .header {
                padding: 0.5rem;
            }
            
            .room-info {
                gap: 0.5rem;
            }
        }
        
        /* Responsive design for tablets */
        @media (min-width: 769px) and (max-width: 1024px) {
            .video-grid {
                grid-template-columns: 1fr;
                gap: 1rem;
            }
            
            .main-container {
                padding: 1rem;
            }
            
            .video-card {
                max-height: 40vh;
            }
        }
        
        /* Larger screens */
        @media (min-width: 1025px) {
            .video-grid {
                grid-template-columns: 1fr 1fr;
            }
        }
        
        /* Toggle button for self-view expansion */
        .expand-btn {
            position: absolute;
            bottom: 5px;
            right: 5px;
            width: 30px;
            height: 30px;
            background: rgba(0, 0, 0, 0.7);
            border: 1px solid rgba(255, 255, 255, 0.2);
            border-radius: 50%;
            color: white;
            font-size: 14px;
            cursor: pointer;
            display: none;
            align-items: center;
            justify-content: center;
            z-index: 10;
            transition: all 0.2s ease;
        }
        
        @media (max-width: 768px) {
            .video-card:first-child .expand-btn {
                display: flex;
            }
        }
        
        .expand-btn:hover {
            background: rgba(0, 0, 0, 0.9);
            transform: scale(1.1);
        }
        
        /* Expanded self-view state */
        .video-card.expanded {
            width: calc(100vw - 20px) !important;
            height: calc(50vh - 20px) !important;
            top: 50% !important;
            left: 50% !important;
            right: auto !important;
            transform: translate(-50%, -50%);
            z-index: 95;
        }
        
        .video-card.expanded .video-overlay {
            display: flex !important;
        }
        
        .video-card.expanded .expand-btn {
            font-size: 18px;
        }
        
        /* Loading spinner */
        .spinner {
            width: 40px;
            height: 40px;
            border: 3px solid var(--glass-border);
            border-top-color: var(--text-primary);
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }
        
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
        
        /* Transcript Panel */
        .transcript-panel {
            position: fixed;
            right: 20px;
            top: 100px;
            bottom: 110px;
            width: 380px;
            background: var(--glass-bg);
            backdrop-filter: blur(20px);
            border: 1px solid var(--glass-border);
            border-radius: 20px;
            display: none;
            flex-direction: column;
            overflow: hidden;
            z-index: 90;
            transition: transform 0.3s ease, opacity 0.3s ease;
        }
        
        .transcript-panel.active {
            display: flex;
        }
        
        .transcript-header {
            padding: 1rem 1.5rem;
            background: var(--glass-bg);
            border-bottom: 1px solid var(--glass-border);
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .transcript-title {
            font-weight: 600;
            color: var(--text-primary);
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .transcript-status {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            font-size: 0.75rem;
            color: var(--text-secondary);
        }
        
        .transcript-status-dot {
            width: 6px;
            height: 6px;
            background: var(--success);
            border-radius: 50%;
            animation: pulse 2s ease-in-out infinite;
        }
        
        .transcript-content {
            flex: 1;
            overflow-y: auto;
            padding: 1rem;
            scroll-behavior: smooth;
        }
        
        .transcript-content::-webkit-scrollbar {
            width: 6px;
        }
        
        .transcript-content::-webkit-scrollbar-track {
            background: var(--glass-bg);
            border-radius: 3px;
        }
        
        .transcript-content::-webkit-scrollbar-thumb {
            background: var(--glass-border);
            border-radius: 3px;
        }
        
        .transcript-content::-webkit-scrollbar-thumb:hover {
            background: var(--text-secondary);
        }
        
        .transcript-entry {
            margin-bottom: 1rem;
            padding: 0.75rem;
            background: rgba(255, 255, 255, 0.02);
            border-radius: 12px;
            border-left: 3px solid transparent;
            transition: all 0.3s ease;
            animation: fadeInUp 0.3s ease;
        }
        
        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }
        
        .transcript-entry.local {
            border-left-color: var(--primary-gradient);
            background: linear-gradient(90deg, rgba(102, 126, 234, 0.05) 0%, transparent 100%);
        }
        
        .transcript-entry.remote {
            border-left-color: var(--secondary-gradient);
            background: linear-gradient(90deg, rgba(240, 147, 251, 0.05) 0%, transparent 100%);
        }
        
        .transcript-entry.system {
            border-left-color: var(--warning);
            background: linear-gradient(90deg, rgba(245, 158, 11, 0.05) 0%, transparent 100%);
            font-style: italic;
        }
        
        .transcript-speaker {
            font-size: 0.75rem;
            font-weight: 600;
            color: var(--text-secondary);
            margin-bottom: 0.25rem;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }
        
        .transcript-text {
            font-size: 0.9rem;
            color: var(--text-primary);
            line-height: 1.5;
            word-wrap: break-word;
        }
        
        .transcript-timestamp {
            font-size: 0.65rem;
            color: var(--muted);
            margin-top: 0.25rem;
            font-variant-numeric: tabular-nums;
        }
        
        .transcript-toggle-btn {
            position: fixed;
            right: 20px;
            top: 50%;
            transform: translateY(-50%);
            width: 40px;
            height: 60px;
            background: var(--glass-bg);
            backdrop-filter: blur(10px);
            border: 1px solid var(--glass-border);
            border-radius: 20px 0 0 20px;
            border-right: none;
            cursor: pointer;
            display: none; /* Hide by default - will show via JS for interviewer only */
            align-items: center;
            justify-content: center;
            font-size: 1.2rem;
            color: var(--text-primary);
            transition: all 0.3s ease;
            z-index: 91;
        }
        
        .transcript-toggle-btn:hover {
            background: var(--primary-gradient);
            transform: translateY(-50%) translateX(-2px);
        }
        
        .transcript-toggle-btn.panel-open {
            right: 400px;
            border-radius: 0 20px 20px 0;
            border-left: none;
            border-right: 1px solid var(--glass-border);
        }
        
        .transcript-empty {
            text-align: center;
            color: var(--text-secondary);
            padding: 2rem;
            font-size: 0.875rem;
        }
        
        .transcript-listening {
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 0.5rem;
            background: rgba(16, 185, 129, 0.1);
            border-radius: 10px;
            margin-bottom: 1rem;
            animation: pulse 2s ease-in-out infinite;
        }
        
        .transcript-listening-text {
            color: var(--success);
            font-size: 0.75rem;
            font-weight: 600;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        /* Adjust main container when transcript panel is open */
        .main-container.transcript-open {
            padding-right: 420px;
        }
        
        /* Responsive adjustments */
        @media (max-width: 1400px) {
            .transcript-panel {
                width: 320px;
            }
            
            .transcript-toggle-btn.panel-open {
                right: 340px;
            }
            
            .main-container.transcript-open {
                padding-right: 360px;
            }
        }
        
        @media (max-width: 1024px) {
            .transcript-panel {
                width: 100%;
                right: 0;
                left: 0;
                top: auto;
                bottom: 70px;
                height: 250px;
                border-radius: 20px 20px 0 0;
            }
            
            .transcript-toggle-btn {
                display: none;
            }
            
            .main-container.transcript-open {
                padding-right: 2rem;
                padding-bottom: 270px;
            }
        }
        
        @media (max-width: 768px) {
            .transcript-panel {
                width: 100%;
                height: 40vh;
                bottom: 70px;
            }
            
            .transcript-toggle-btn {
                /* Keep button visible on mobile for debugging */
                bottom: 100px;
                top: auto;
                transform: none;
            }
        }
    </style>
</head>
<body>
    <!-- Header -->
    <div class="header">
        <div class="room-info">
            <div class="room-badge">Interview Room</div>
            <div id="roomCode" style="color: var(--text-secondary); font-size: 0.875rem;"></div>
        </div>
        <div class="connection-status">
            <div class="status-dot" id="statusDot"></div>
            <span id="statusText">Connecting...</span>
        </div>
    </div>
    
    <!-- Main Container -->
    <div class="main-container" id="mainContainer">
        <div class="video-grid">
            <!-- Local Video -->
            <div class="video-card" id="localVideoCard">
                <video id="localVideo" autoplay muted playsinline></video>
                <button class="expand-btn" id="expandBtn" title="Toggle size">‚§¢</button>
                <div class="video-overlay">
                    <div class="participant-info">
                        <div class="participant-avatar" id="localAvatar">Y</div>
                        <div class="participant-details">
                            <div class="participant-name">You</div>
                            <div class="participant-role" id="localRole">Connecting...</div>
                        </div>
                    </div>
                    <div class="audio-indicator" id="localAudioIndicator">
                        <div class="audio-bars" id="localAudioBars" style="display: none;">
                            <div class="audio-bar"></div>
                            <div class="audio-bar"></div>
                            <div class="audio-bar"></div>
                            <div class="audio-bar"></div>
                        </div>
                        <span class="muted-indicator" id="localMutedIcon" style="display: none;">üîá</span>
                    </div>
                </div>
                <div class="video-placeholder" id="localPlaceholder">
                    <div class="placeholder-icon">üìπ</div>
                    <div class="placeholder-text">Requesting camera access...</div>
                </div>
            </div>
            
            <!-- Remote Video -->
            <div class="video-card" id="remoteVideoCard">
                <video id="remoteVideo" autoplay playsinline></video>
                <div class="video-overlay">
                    <div class="participant-info">
                        <div class="participant-avatar" id="remoteAvatar">P</div>
                        <div class="participant-details">
                            <div class="participant-name" id="remoteName">Participant</div>
                            <div class="participant-role" id="remoteRole">Waiting...</div>
                        </div>
                    </div>
                    <div class="audio-indicator" id="remoteAudioIndicator">
                        <div class="audio-bars" id="remoteAudioBars" style="display: none;">
                            <div class="audio-bar"></div>
                            <div class="audio-bar"></div>
                            <div class="audio-bar"></div>
                            <div class="audio-bar"></div>
                        </div>
                        <span class="muted-indicator" id="remoteMutedIcon" style="display: none;">üîá</span>
                    </div>
                </div>
                <div class="video-placeholder" id="remotePlaceholder">
                    <div class="placeholder-icon">üë§</div>
                    <div class="placeholder-text">Waiting for participant...</div>
                </div>
            </div>
        </div>
    </div>
    
    <!-- Transcript Panel -->
    <button class="transcript-toggle-btn" id="transcriptToggle" title="Toggle Transcript">
        <span>üí¨</span>
    </button>
    
    <div class="transcript-panel" id="transcriptPanel">
        <div class="transcript-header">
            <div class="transcript-title">
                <span>Live Transcript</span>
            </div>
            <div class="transcript-status">
                <div class="transcript-status-dot"></div>
                <span id="transcriptStatus">Listening</span>
            </div>
        </div>
        <div class="transcript-content" id="transcriptContent">
            <div class="transcript-empty">
                Transcript will appear here as you speak...
            </div>
        </div>
    </div>
    
    <!-- Control Bar -->
    <div class="control-bar">
        <div class="recording-indicator" id="recordingIndicator">
            <div class="recording-dot"></div>
            <span>Recording in Progress</span>
        </div>
        
        <div class="timer" id="callTimer">00:00</div>
        
        <div class="control-group">
            <button class="control-btn" id="toggleVideo">
                <span>üìπ</span>
                <span class="control-label">Camera</span>
            </button>
            <button class="control-btn" id="toggleAudio">
                <span>üé§</span>
                <span class="control-label">Microphone</span>
            </button>
        </div>
        
        <div class="control-group" id="recordingControls" style="display: none;">
            <button class="control-btn" id="startRecording">
                <span>‚è∫Ô∏è</span>
                <span class="control-label">Start</span>
            </button>
            <button class="control-btn recording" id="stopRecording" style="display: none;">
                <span>‚èπÔ∏è</span>
                <span class="control-label">Stop</span>
            </button>
        </div>
        
        <div class="control-group">
            <button class="control-btn" id="transcriptControlBtn" title="Toggle Transcript">
                <span>üí¨</span>
                <span class="control-label">Transcript</span>
            </button>
        </div>
        
        <div class="control-group">
            <button class="control-btn end-call-btn" id="endCall">
                <span>üìû</span>
                <span class="control-label">End Call</span>
            </button>
        </div>
    </div>

    <script src="/socket.io/socket.io.js"></script>
    <script src="https://sdk.twilio.com/js/video/releases/2.27.0/twilio-video.min.js"></script>
    <script>
        // Get room ID from URL
        const urlPath = window.location.pathname;
        const roomId = urlPath.split('/').pop();
        document.getElementById('roomCode').textContent = `Room: ${roomId.substring(0, 8)}`;
        
        const socket = io();
        const localVideo = document.getElementById('localVideo');
        const remoteVideo = document.getElementById('remoteVideo');
        const statusDot = document.getElementById('statusDot');
        const statusText = document.getElementById('statusText');
        
        let localStream;
        let remoteStream;
        let peerConnection;
        let makingOffer = false;
        let ignoreOffer = false;
        let isSettingRemoteAnswerPending = false;
        let pendingCandidates = [];
        
        // Audio/Video state
        let isVideoEnabled = true;
        let isAudioEnabled = true;
        let remoteAudioMuted = false;
        
        // Twilio recording variables
        let isRecording = false;
        let twilioRoom = null;
        let twilioConnected = false;
        let twilioLocalAudioTrack = null;  // Store reference to Twilio audio track
        
        // Call timer
        let callStartTime = null;
        let timerInterval = null;
        
        // Check if this user is the interviewer
        const urlParams = new URLSearchParams(window.location.search);
        const isCreator = urlParams.get('creator') === 'true';
        const isInterviewer = isCreator || sessionStorage.getItem(`room_creator_${roomId}`) === 'true';
        
        if (isCreator) {
            sessionStorage.setItem(`room_creator_${roomId}`, 'true');
        }
        
        // Update UI based on role
        if (isInterviewer) {
            document.getElementById('localRole').textContent = 'Interviewer';
            document.getElementById('remoteRole').textContent = 'Interviewee';
            document.getElementById('localAvatar').textContent = 'I';
            document.getElementById('remoteAvatar').textContent = 'C';
            document.getElementById('recordingControls').style.display = 'flex';
            // Show sidebar transcript toggle for interviewer on desktop
            if (window.innerWidth > 768) {
                document.getElementById('transcriptToggle').style.display = 'flex';
            }
        } else {
            document.getElementById('localRole').textContent = 'Interviewee';
            document.getElementById('remoteRole').textContent = 'Interviewer';
            document.getElementById('localAvatar').textContent = 'C';
            document.getElementById('remoteAvatar').textContent = 'I';
            // Hide sidebar toggle for interviewee - they use control bar button
            document.getElementById('transcriptToggle').style.display = 'none';
        }
        
        const configuration = {
            iceServers: [
                { urls: 'stun:stun.l.google.com:19302' },
                { urls: 'stun:stun1.l.google.com:19302' }
            ]
        };
        
        // Initialize media
        async function initializeMedia() {
            try {
                statusText.textContent = 'Accessing camera...';
                
                localStream = await navigator.mediaDevices.getUserMedia({
                    video: { 
                        width: { ideal: 1280 },
                        height: { ideal: 720 },
                        facingMode: 'user'
                    },
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });
                
                localVideo.srcObject = localStream;
                document.getElementById('localPlaceholder').style.display = 'none';
                
                // Monitor local audio levels
                monitorAudioLevel(localStream, 'local');
                
                statusText.textContent = 'Ready';
                
                // Join room after getting media
                socket.emit('join-room', roomId);
                
            } catch (error) {
                console.error('Error accessing media:', error);
                statusText.textContent = 'Camera access denied';
                document.getElementById('localPlaceholder').querySelector('.placeholder-text').textContent = 'Camera access denied';
            }
        }
        
        // Monitor audio levels for visual feedback
        function monitorAudioLevel(stream, type) {
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const analyser = audioContext.createAnalyser();
            const microphone = audioContext.createMediaStreamSource(stream);
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            
            analyser.smoothingTimeConstant = 0.8;
            analyser.fftSize = 1024;
            
            microphone.connect(analyser);
            
            const checkAudio = () => {
                analyser.getByteFrequencyData(dataArray);
                const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
                
                const bars = document.getElementById(`${type}AudioBars`);
                const mutedIcon = document.getElementById(`${type}MutedIcon`);
                
                if (type === 'local' && !isAudioEnabled) {
                    bars.style.display = 'none';
                    mutedIcon.style.display = 'block';
                } else if (type === 'remote' && remoteAudioMuted) {
                    bars.style.display = 'none';
                    mutedIcon.style.display = 'block';
                } else if (average > 10) {
                    bars.style.display = 'flex';
                    mutedIcon.style.display = 'none';
                    document.getElementById(`${type}VideoCard`).classList.add('speaking');
                } else {
                    bars.style.display = 'none';
                    mutedIcon.style.display = 'none';
                    document.getElementById(`${type}VideoCard`).classList.remove('speaking');
                }
                
                requestAnimationFrame(checkAudio);
            };
            
            checkAudio();
        }
        
        // Socket event handlers
        socket.on('room-joined', (data) => {
            console.log('Joined room:', data);
            statusText.textContent = 'Waiting for participant...';
        });
        
        socket.on('user-connected', async (userId) => {
            console.log('User connected:', userId);
            statusText.textContent = 'Participant joined';
            
            // Auto-enable transcription for BOTH participants when connected
            console.log('[AUTO-TRANSCRIPT] Remote participant connected, enabling auto-transcription...');
            console.log('[AUTO-TRANSCRIPT] Current role:', isInterviewer ? 'INTERVIEWER' : 'INTERVIEWEE');
            
            // Check if iOS device
            const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent) && !window.MSStream;
            if (isIOS) {
                console.log('[AUTO-TRANSCRIPT] iOS device detected - skipping auto-transcription (not supported)');
            }
            
            setTimeout(() => {
                if (!autoTranscriptionEnabled && isAudioEnabled && !isIOS) {
                    console.log('[AUTO-TRANSCRIPT] Starting background transcription for', isInterviewer ? 'INTERVIEWER' : 'INTERVIEWEE');
                    autoTranscriptionEnabled = true;
                    
                    // Start speech recognition for BOTH interviewer and interviewee
                    if (!isTranscribing) {
                        console.log('[AUTO-TRANSCRIPT] Calling startSpeechRecognition() for', isInterviewer ? 'INTERVIEWER' : 'INTERVIEWEE');
                        startSpeechRecognition();
                    }
                    
                    // Only auto-open transcript panel for interviewer
                    if (isInterviewer && !isTranscriptOpen) {
                        console.log('[AUTO-TRANSCRIPT] Auto-opening transcript panel for INTERVIEWER');
                        if (window.innerWidth > 768) {
                            // Use sidebar toggle on desktop
                            transcriptToggle.click();
                        } else {
                            // Use control button on mobile
                            toggleTranscriptPanel();
                        }
                    } else if (!isInterviewer) {
                        console.log('[AUTO-TRANSCRIPT] INTERVIEWEE: Transcription running in background (panel not auto-opened)');
                    }
                    
                    // Notify about transcription status
                    console.log('[AUTO-TRANSCRIPT] Transcription now ACTIVE for:', isInterviewer ? 'INTERVIEWER' : 'INTERVIEWEE');
                }
            }, 2000); // Wait 2 seconds for connection to stabilize
            
            if (!peerConnection) {
                await setupPeerConnection();
            }
            
            await createAndSendOffer();
        });
        
        socket.on('offer', async (data) => {
            console.log('Received offer');
            
            if (!peerConnection) {
                await setupPeerConnection();
            }
            
            try {
                const offerCollision = makingOffer || peerConnection.signalingState !== "stable";
                ignoreOffer = offerCollision;
                
                if (ignoreOffer) {
                    return;
                }
                
                await peerConnection.setRemoteDescription(data.offer);
                const answer = await peerConnection.createAnswer();
                await peerConnection.setLocalDescription(answer);
                
                socket.emit('answer', {
                    answer: answer,
                    to: data.from
                });
                
                // Send mute state
                socket.emit('audio-state', {
                    roomId: roomId,
                    muted: !isAudioEnabled
                });
                
                if (pendingCandidates.length > 0) {
                    for (const candidate of pendingCandidates) {
                        await peerConnection.addIceCandidate(candidate);
                    }
                    pendingCandidates = [];
                }
                
            } catch (error) {
                console.error('Error handling offer:', error);
            }
        });
        
        socket.on('answer', async (data) => {
            try {
                const readyForAnswer = !isSettingRemoteAnswerPending && peerConnection.signalingState === "have-local-offer";
                
                if (!readyForAnswer) {
                    return;
                }
                
                isSettingRemoteAnswerPending = true;
                await peerConnection.setRemoteDescription(data.answer);
                isSettingRemoteAnswerPending = false;
                
                if (pendingCandidates.length > 0) {
                    for (const candidate of pendingCandidates) {
                        await peerConnection.addIceCandidate(candidate);
                    }
                    pendingCandidates = [];
                }
                
            } catch (error) {
                console.error('Error handling answer:', error);
                isSettingRemoteAnswerPending = false;
            }
        });
        
        socket.on('ice-candidate', async (data) => {
            try {
                if (!peerConnection || !peerConnection.remoteDescription) {
                    pendingCandidates.push(data.candidate);
                    return;
                }
                
                await peerConnection.addIceCandidate(data.candidate);
            } catch (error) {
                console.error('Error adding ICE candidate:', error);
            }
        });
        
        socket.on('audio-state', (data) => {
            console.log('Remote audio state:', data.muted ? 'muted' : 'unmuted');
            remoteAudioMuted = data.muted;
            
            const remoteBars = document.getElementById('remoteAudioBars');
            const remoteMuted = document.getElementById('remoteMutedIcon');
            
            if (data.muted) {
                remoteBars.style.display = 'none';
                remoteMuted.style.display = 'block';
                
                // Add notification to transcript when remote user mutes
                if (isTranscriptOpen) {
                    const remoteSpeaker = isInterviewer ? 'Interviewee' : 'Interviewer';
                    addTranscriptEntry('System', `üîá ${remoteSpeaker} muted their microphone`, 'system');
                }
            } else {
                remoteMuted.style.display = 'none';
                
                // Add notification to transcript when remote user unmutes
                if (isTranscriptOpen) {
                    const remoteSpeaker = isInterviewer ? 'Interviewee' : 'Interviewer';
                    addTranscriptEntry('System', `üé§ ${remoteSpeaker} unmuted their microphone`, 'system');
                }
            }
        });
        
        socket.on('user-disconnected', (userId) => {
            console.log('User disconnected');
            statusText.textContent = 'Participant left';
            statusDot.classList.remove('connected');
            
            document.getElementById('remotePlaceholder').style.display = 'flex';
            document.getElementById('remotePlaceholder').querySelector('.placeholder-text').textContent = 'Participant disconnected';
            
            if (remoteVideo.srcObject) {
                remoteVideo.srcObject.getTracks().forEach(track => track.stop());
                remoteVideo.srcObject = null;
            }
            
            stopCallTimer();
        });
        
        // Handle recording notification from interviewer
        socket.on('start-recording', async (data) => {
            console.log('[CLIENT] Received start-recording notification from interviewer');
            console.log('[CLIENT] My role: ' + (isInterviewer ? 'INTERVIEWER' : 'INTERVIEWEE'));
            console.log('[CLIENT] Data received:', data);
            
            if (!isInterviewer) {
                console.log('[CLIENT] I am INTERVIEWEE - joining Twilio recording...');
                try {
                    // Show recording indicator for interviewee
                    document.getElementById('recordingIndicator').classList.add('active');
                    // Join Twilio room as interviewee (force flag indicates this is interviewee)
                    console.log('[CLIENT] Calling startTwilioRecording(true) for INTERVIEWEE...');
                    await startTwilioRecording(true);
                    console.log('[CLIENT] INTERVIEWEE successfully joined Twilio recording');
                } catch (error) {
                    console.error('[CLIENT ERROR] INTERVIEWEE failed to join Twilio:', error);
                }
            } else {
                console.log('[CLIENT] I am INTERVIEWER - ignoring notification (I started it)');
            }
        });
        
        socket.on('stop-recording', async (data) => {
            console.log('[CLIENT] Received stop-recording notification');
            if (!isInterviewer && twilioRoom && twilioConnected) {
                console.log('[CLIENT] Interviewee leaving Twilio recording...');
                document.getElementById('recordingIndicator').classList.remove('active');
                twilioRoom.disconnect();
                twilioConnected = false;
            }
        });
        
        // Setup peer connection
        async function setupPeerConnection() {
            peerConnection = new RTCPeerConnection(configuration);
            
            if (localStream) {
                localStream.getTracks().forEach(track => {
                    peerConnection.addTrack(track, localStream);
                });
            }
            
            peerConnection.ontrack = (event) => {
                if (event.streams && event.streams[0]) {
                    remoteStream = event.streams[0];
                    remoteVideo.srcObject = remoteStream;
                    document.getElementById('remotePlaceholder').style.display = 'none';
                    
                    // Monitor remote audio
                    monitorAudioLevel(remoteStream, 'remote');
                    
                    // Update status
                    statusText.textContent = 'Connected';
                    statusDot.classList.add('connected');
                    
                    // Start call timer
                    startCallTimer();
                }
            };
            
            peerConnection.onicecandidate = (event) => {
                if (event.candidate) {
                    socket.emit('ice-candidate', {
                        candidate: event.candidate,
                        roomId: roomId
                    });
                }
            };
            
            peerConnection.onconnectionstatechange = () => {
                switch(peerConnection.connectionState) {
                    case 'connected':
                        statusText.textContent = 'Connected';
                        statusDot.classList.add('connected');
                        break;
                    case 'disconnected':
                        statusText.textContent = 'Reconnecting...';
                        statusDot.classList.remove('connected');
                        break;
                    case 'failed':
                        statusText.textContent = 'Connection failed';
                        statusDot.classList.remove('connected');
                        break;
                }
            };
            
            peerConnection.onnegotiationneeded = async () => {
                try {
                    await createAndSendOffer();
                } catch (error) {
                    console.error('Error in negotiation:', error);
                }
            };
        }
        
        async function createAndSendOffer() {
            try {
                makingOffer = true;
                await peerConnection.setLocalDescription();
                
                socket.emit('offer', {
                    offer: peerConnection.localDescription,
                    roomId: roomId
                });
                
                // Send initial mute state
                socket.emit('audio-state', {
                    roomId: roomId,
                    muted: !isAudioEnabled
                });
            } finally {
                makingOffer = false;
            }
        }
        
        // Call timer functions
        function startCallTimer() {
            if (callStartTime) return;
            
            callStartTime = Date.now();
            document.getElementById('callTimer').classList.add('active');
            
            timerInterval = setInterval(() => {
                const elapsed = Math.floor((Date.now() - callStartTime) / 1000);
                const minutes = Math.floor(elapsed / 60).toString().padStart(2, '0');
                const seconds = (elapsed % 60).toString().padStart(2, '0');
                document.getElementById('callTimer').textContent = `${minutes}:${seconds}`;
            }, 1000);
        }
        
        function stopCallTimer() {
            if (timerInterval) {
                clearInterval(timerInterval);
                timerInterval = null;
            }
            callStartTime = null;
            document.getElementById('callTimer').classList.remove('active');
        }
        
        // Control buttons
        document.getElementById('toggleVideo').addEventListener('click', () => {
            const videoTrack = localStream.getVideoTracks()[0];
            if (videoTrack) {
                isVideoEnabled = !isVideoEnabled;
                videoTrack.enabled = isVideoEnabled;
                
                const btn = document.getElementById('toggleVideo');
                if (!isVideoEnabled) {
                    btn.classList.add('muted');
                    btn.innerHTML = '<span>üìπ</span><span class="control-label">Camera Off</span>';
                    localVideo.style.opacity = '0.1';
                } else {
                    btn.classList.remove('muted');
                    btn.innerHTML = '<span>üìπ</span><span class="control-label">Camera</span>';
                    localVideo.style.opacity = '1';
                }
            }
        });
        
        document.getElementById('toggleAudio').addEventListener('click', () => {
            const audioTrack = localStream.getAudioTracks()[0];
            if (audioTrack) {
                isAudioEnabled = !isAudioEnabled;
                audioTrack.enabled = isAudioEnabled;
                
                // CRITICAL: Stop/start speech recognition based on mute state
                if (!isAudioEnabled) {
                    // STOP transcription when muted
                    console.log('[MUTE] Stopping speech recognition - user muted');
                    if (recognition) {
                        recognition.abort(); // Use abort() instead of stop() for immediate termination
                        isTranscribing = false;
                    }
                    // Add a system message to transcript
                    if (isTranscriptOpen) {
                        addTranscriptEntry('System', 'üîá Microphone muted - transcription paused', 'system');
                        transcriptStatus.textContent = 'Muted';
                    }
                } else {
                    // RESTART transcription when unmuted (if panel is open OR auto-transcription is enabled)
                    console.log('[MUTE] Restarting speech recognition - user unmuted');
                    if (isTranscriptOpen || autoTranscriptionEnabled) {
                        // Small delay to ensure clean restart after abort
                        setTimeout(() => {
                            if (!isTranscribing && isAudioEnabled) {
                                if (isTranscriptOpen) {
                                    addTranscriptEntry('System', 'üé§ Microphone unmuted - transcription resumed', 'system');
                                }
                                startSpeechRecognition();
                            }
                        }, 100);
                    }
                }
                
                // ALSO mute/unmute the Twilio track if recording
                if (twilioLocalAudioTrack) {
                    if (!isAudioEnabled) {
                        console.log('[MUTE] Disabling Twilio audio track');
                        twilioLocalAudioTrack.disable();
                    } else {
                        console.log('[MUTE] Enabling Twilio audio track');
                        twilioLocalAudioTrack.enable();
                    }
                }
                
                const btn = document.getElementById('toggleAudio');
                if (!isAudioEnabled) {
                    btn.classList.add('muted');
                    btn.innerHTML = '<span>üîá</span><span class="control-label">Muted</span>';
                } else {
                    btn.classList.remove('muted');
                    btn.innerHTML = '<span>üé§</span><span class="control-label">Microphone</span>';
                }
                
                // Notify remote peer of mute state
                socket.emit('audio-state', {
                    roomId: roomId,
                    muted: !isAudioEnabled
                });
                
                // Update local audio indicator
                const localBars = document.getElementById('localAudioBars');
                const localMuted = document.getElementById('localMutedIcon');
                if (!isAudioEnabled) {
                    localBars.style.display = 'none';
                    localMuted.style.display = 'block';
                } else {
                    localMuted.style.display = 'none';
                }
            }
        });
        
        document.getElementById('startRecording').addEventListener('click', () => {
            startRecording();
        });
        
        document.getElementById('stopRecording').addEventListener('click', () => {
            stopRecording();
        });
        
        document.getElementById('endCall').addEventListener('click', () => {
            if (confirm('Are you sure you want to end the call?')) {
                if (isRecording) {
                    stopRecording();
                }
                
                if (localStream) {
                    localStream.getTracks().forEach(track => track.stop());
                }
                if (peerConnection) {
                    peerConnection.close();
                }
                socket.disconnect();
                window.location.href = '/';
            }
        });
        
        // Twilio recording functions
        async function startTwilioRecording(forceStart = false) {
            // Allow non-interviewers to join if notified
            if (!isInterviewer && !forceStart) {
                console.log('[CLIENT TWILIO] Not interviewer and not forced, skipping recording');
                return;
            }
            
            try {
                console.log('[CLIENT TWILIO] ========================================');
                console.log('[CLIENT TWILIO] Starting recording process...');
                console.log('[CLIENT TWILIO] Room ID:', roomId);
                console.log('[CLIENT TWILIO] User role (isInterviewer):', isInterviewer);
                console.log('[CLIENT TWILIO] Force start (interviewee notified):', forceStart);
                
                // When forceStart is true, it means the interviewee was notified to join
                // So we need to send the CORRECT identity
                const actualRole = forceStart ? false : isInterviewer;
                console.log('[CLIENT TWILIO] Sending role to server:', actualRole ? 'interviewer' : 'interviewee');
                
                const response = await fetch('/api/twilio/start', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ 
                        roomId,
                        isInterviewer: actualRole
                    })
                });
                
                console.log('[CLIENT TWILIO] Server response status:', response.status);
                const data = await response.json();
                console.log('[CLIENT TWILIO] Server response data:', data);
                
                if (!data.success) {
                    console.error('[CLIENT TWILIO ERROR] Failed to start recording:', data.error);
                    alert(`Failed to start recording: ${data.error}`);
                    return;
                }
                
                // Use the token from response
                const token = data.token;
                const roomName = data.room?.name || data.roomName;
                const identity = data.identity;
                
                console.log('[CLIENT TWILIO] Token received:', token ? 'Yes' : 'No');
                console.log('[CLIENT TWILIO] Identity:', identity);
                console.log('[CLIENT TWILIO] Room name:', roomName);
                
                if (!token) {
                    console.error('[CLIENT TWILIO ERROR] No token received');
                    alert('Failed to get recording token. Please try again.');
                    return;
                }
                
                console.log('[CLIENT TWILIO] Connecting to Twilio Video room...');
                twilioRoom = await Twilio.Video.connect(token, {
                    name: roomName,
                    audio: true,
                    video: false,
                    dominantSpeaker: true
                });
                
                console.log('[CLIENT TWILIO] Connected to Twilio room:', twilioRoom.name);
                console.log('[CLIENT TWILIO] Twilio room SID:', twilioRoom.sid);
                console.log('[CLIENT TWILIO] Local participant:', twilioRoom.localParticipant.identity);
                
                if (localStream) {
                    const audioTrack = localStream.getAudioTracks()[0];
                    if (audioTrack) {
                        console.log('[CLIENT TWILIO] Publishing local audio track to Twilio...');
                        twilioLocalAudioTrack = new Twilio.Video.LocalAudioTrack(audioTrack);
                        await twilioRoom.localParticipant.publishTrack(twilioLocalAudioTrack);
                        console.log('[CLIENT TWILIO] Audio track published');
                        
                        // If currently muted, disable the Twilio track too
                        if (!isAudioEnabled) {
                            console.log('[CLIENT TWILIO] Audio is muted, disabling Twilio track');
                            twilioLocalAudioTrack.disable();
                        }
                    } else {
                        console.warn('[CLIENT TWILIO WARNING] No local audio track found');
                    }
                } else {
                    console.warn('[CLIENT TWILIO WARNING] No local stream available');
                }
                
                twilioConnected = true;
                console.log('[CLIENT TWILIO] Recording started successfully');
                console.log('[CLIENT TWILIO] ========================================');
                
            } catch (error) {
                console.error('[CLIENT TWILIO ERROR] ========================================');
                console.error('[CLIENT TWILIO ERROR] Failed to start:', error.message);
                console.error('[CLIENT TWILIO ERROR] Stack:', error.stack);
                console.error('[CLIENT TWILIO ERROR] ========================================');
                alert(`Failed to start recording: ${error.message}`);
            }
        }
        
        async function stopTwilioRecording() {
            if (!twilioRoom || !twilioConnected) {
                console.log('[CLIENT TWILIO] No active Twilio room to stop');
                return;
            }
            
            try {
                console.log('[CLIENT TWILIO] ========================================');
                console.log('[CLIENT TWILIO] Stopping recording...');
                console.log('[CLIENT TWILIO] Room ID:', roomId);
                console.log('[CLIENT TWILIO] Twilio Room:', twilioRoom.name);
                console.log('[CLIENT TWILIO] Is Interviewer:', isInterviewer);
                
                console.log('[CLIENT TWILIO] Disconnecting from Twilio room...');
                twilioRoom.disconnect();
                twilioConnected = false;
                twilioLocalAudioTrack = null;  // Clear the reference
                console.log('[CLIENT TWILIO] Disconnected from Twilio');
                
                // Only the interviewer should call the stop endpoint
                // The interviewee just disconnects from Twilio
                if (!isInterviewer) {
                    console.log('[CLIENT TWILIO] Interviewee - not calling stop endpoint, just disconnecting');
                    console.log('[CLIENT TWILIO] ========================================');
                    return;
                }
                
                console.log('[CLIENT TWILIO] Interviewer - calling stop endpoint...');
                
                // Add timeout to prevent hanging
                const controller = new AbortController();
                const timeoutId = setTimeout(() => controller.abort(), 60000); // 60 second timeout for downloading recordings
                
                // Gather all transcript entries before sending
                console.log('[CLIENT TWILIO] Gathering transcript entries...');
                console.log('[CLIENT TWILIO] Total transcript entries:', transcriptEntries.length);
                
                let response;
                try {
                    response = await fetch('/api/twilio/stop', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ 
                            roomId,
                            transcriptEntries: transcriptEntries // Send collected transcripts
                        }),
                        signal: controller.signal
                    });
                    clearTimeout(timeoutId);
                } catch (fetchError) {
                    clearTimeout(timeoutId);
                    console.error('[CLIENT TWILIO ERROR] Fetch failed:', fetchError);
                    
                    if (fetchError.name === 'AbortError') {
                        console.error('[CLIENT TWILIO ERROR] Request timed out after 60 seconds');
                        alert('Recording stop timed out. The recording is likely still being processed. Please check the recordings list in a minute.');
                        return;
                    } else if (fetchError.message.includes('Failed to fetch')) {
                        console.error('[CLIENT TWILIO ERROR] Network error - server may be busy or connection lost');
                        alert('Connection lost while stopping recording. The recording may have been saved. Please check the recordings list.');
                        return;
                    }
                    throw fetchError;
                }
                
                console.log('[CLIENT TWILIO] Server response status:', response.status);
                
                if (!response.ok) {
                    const errorText = await response.text();
                    console.error('[CLIENT TWILIO ERROR] Server error:', errorText);
                    throw new Error(`Server error (${response.status}): ${errorText}`);
                }
                
                const data = await response.json();
                console.log('[CLIENT TWILIO] Server response data:', data);
                
                if (data.success) {
                    console.log('[CLIENT TWILIO] Recording saved successfully');
                    console.log('[CLIENT TWILIO] Message:', data.message);
                    console.log('[CLIENT TWILIO] Downloaded files:', data.recordings);
                    
                    if (data.recordings && data.recordings.length > 0) {
                        // Show the message from server which indicates transcription is in progress
                        alert(data.message || `Recording saved! ${data.recordings.length} file(s) downloaded.`);
                    } else if (data.message) {
                        alert(data.message);
                    } else {
                        alert('Recording stopped but no files were saved. Check server logs.');
                    }
                } else {
                    console.error('[CLIENT TWILIO ERROR] Failed to save recording:', data.error);
                    alert(`Failed to save recording: ${data.error}`);
                }
                
                console.log('[CLIENT TWILIO] ========================================');
                
            } catch (error) {
                console.error('[CLIENT TWILIO ERROR] ========================================');
                console.error('[CLIENT TWILIO ERROR] Failed to stop:', error.message);
                console.error('[CLIENT TWILIO ERROR] Stack:', error.stack);
                console.error('[CLIENT TWILIO ERROR] ========================================');
                alert(`Error stopping recording: ${error.message}`);
            }
        }
        
        function startRecording() {
            if (!localStream || !isInterviewer) return;
            
            isRecording = true;
            
            document.getElementById('startRecording').style.display = 'none';
            document.getElementById('stopRecording').style.display = 'flex';
            document.getElementById('recordingIndicator').classList.add('active');
            
            // Notify other participant to join Twilio recording
            socket.emit('start-recording', { roomId });
            
            startTwilioRecording();
        }
        
        function stopRecording() {
            if (!isRecording) return;
            
            isRecording = false;
            
            document.getElementById('startRecording').style.display = 'flex';
            document.getElementById('stopRecording').style.display = 'none';
            document.getElementById('recordingIndicator').classList.remove('active');
            
            // Notify other participant to stop Twilio recording
            socket.emit('stop-recording', { roomId });
            
            stopTwilioRecording();
        }
        
        // Cleanup on page unload
        window.addEventListener('beforeunload', () => {
            if (isRecording && twilioRoom && twilioConnected) {
                twilioRoom.disconnect();
            }
            
            if (localStream) {
                localStream.getTracks().forEach(track => track.stop());
            }
            if (peerConnection) {
                peerConnection.close();
            }
        });
        
        // Start the application
        initializeMedia();
        
        // Mobile self-view expand/collapse functionality
        const expandBtn = document.getElementById('expandBtn');
        const localVideoCard = document.getElementById('localVideoCard');
        let isExpanded = false;
        
        expandBtn.addEventListener('click', (e) => {
            e.stopPropagation();
            isExpanded = !isExpanded;
            
            if (isExpanded) {
                localVideoCard.classList.add('expanded');
                expandBtn.innerHTML = '‚§¶';
                expandBtn.title = 'Minimize';
            } else {
                localVideoCard.classList.remove('expanded');
                expandBtn.innerHTML = '‚§¢';
                expandBtn.title = 'Expand';
            }
        });
        
        // Click outside to minimize expanded video
        document.addEventListener('click', (e) => {
            if (isExpanded && !localVideoCard.contains(e.target)) {
                isExpanded = false;
                localVideoCard.classList.remove('expanded');
                expandBtn.innerHTML = '‚§¢';
                expandBtn.title = 'Expand';
            }
        });
        
        // Real-time Transcript Functionality
        const transcriptPanel = document.getElementById('transcriptPanel');
        const transcriptToggle = document.getElementById('transcriptToggle');
        const transcriptContent = document.getElementById('transcriptContent');
        const transcriptStatus = document.getElementById('transcriptStatus');
        const mainContainer = document.getElementById('mainContainer');
        
        let isTranscriptOpen = false;
        let recognition = null;
        let isTranscribing = false;
        let transcriptEntries = [];
        let interimTranscript = '';
        let currentSpeaker = 'local';
        let autoTranscriptionEnabled = true; // Enable auto-transcription for BOTH participants by default
        
        // Function to toggle transcript panel
        function toggleTranscriptPanel() {
            isTranscriptOpen = !isTranscriptOpen;
            
            if (isTranscriptOpen) {
                transcriptPanel.classList.add('active');
                transcriptToggle.classList.add('panel-open');
                mainContainer.classList.add('transcript-open');
                transcriptToggle.innerHTML = '<span>‚úï</span>';
                
                // Update control button state
                const controlBtn = document.getElementById('transcriptControlBtn');
                if (controlBtn) {
                    controlBtn.classList.add('active');
                }
                
                // Add initial information message
                const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent) && !window.MSStream;
                if (isIOS) {
                    addTranscriptEntry('System', 'üì± iOS device detected - real-time transcription is not supported', 'system');
                    addTranscriptEntry('System', 'üí° Transcription will be available after the recording ends', 'system');
                } else {
                    addTranscriptEntry('System', 'üìù Live transcript is now active', 'system');
                }
                
                if (!isInterviewer) {
                    addTranscriptEntry('System', 'üë§ You are the INTERVIEWEE', 'system');
                } else {
                    addTranscriptEntry('System', 'üëî You are the INTERVIEWER', 'system');
                }
                
                if (!isIOS) {
                    addTranscriptEntry('System', 'üéØ Important: Both participants must enable transcription to see each other\'s speech', 'system');
                }
                
                // Notify remote participant that we have transcript open
                if (socket && socket.connected) {
                    socket.emit('transcript-status', {
                        roomId: roomId,
                        isOpen: true,
                        participant: isInterviewer ? 'Interviewer' : 'Interviewee'
                    });
                }
                
                // Start speech recognition ONLY if not muted and not already started
                if (!isTranscribing && isAudioEnabled) {
                    console.log('[PANEL OPEN] Starting speech recognition for', isInterviewer ? 'INTERVIEWER' : 'INTERVIEWEE');
                    startSpeechRecognition();
                } else if (!isAudioEnabled) {
                    // Show muted status if microphone is muted
                    addTranscriptEntry('System', 'üîá Microphone is muted. Unmute to start transcription.', 'system');
                    transcriptStatus.textContent = 'Muted';
                } else if (isTranscribing) {
                    console.log('[PANEL OPEN] Speech recognition already running for', isInterviewer ? 'INTERVIEWER' : 'INTERVIEWEE');
                    addTranscriptEntry('System', '‚úÖ Speech recognition is active', 'system');
                }
            } else {
                transcriptPanel.classList.remove('active');
                transcriptToggle.classList.remove('panel-open');
                mainContainer.classList.remove('transcript-open');
                transcriptToggle.innerHTML = '<span>üí¨</span>';
                
                // Update control button state
                const controlBtn = document.getElementById('transcriptControlBtn');
                if (controlBtn) {
                    controlBtn.classList.remove('active');
                }
                
                // Notify remote participant that we closed transcript
                if (socket && socket.connected) {
                    socket.emit('transcript-status', {
                        roomId: roomId,
                        isOpen: false,
                        participant: isInterviewer ? 'Interviewer' : 'Interviewee'
                    });
                }
            }
        }
        
        // Toggle transcript panel - sidebar button
        transcriptToggle.addEventListener('click', toggleTranscriptPanel);
        
        // Toggle transcript panel - control bar button
        const transcriptControlBtn = document.getElementById('transcriptControlBtn');
        if (transcriptControlBtn) {
            transcriptControlBtn.addEventListener('click', toggleTranscriptPanel);
        }
        
        // Initialize Speech Recognition
        function startSpeechRecognition() {
            // CRITICAL: Don't start if microphone is muted
            if (!isAudioEnabled) {
                console.warn('[SPEECH] Cannot start recognition - microphone is muted');
                transcriptStatus.textContent = 'Muted';
                addTranscriptEntry('System', 'üîá Your microphone is muted. Unmute to enable transcription.', 'system');
                return;
            }
            
            // Check if browser is iOS (Safari on iOS doesn't support Web Speech API)
            const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent) && !window.MSStream;
            if (isIOS) {
                console.warn('[SPEECH] iOS detected - Speech recognition not supported on iOS devices');
                console.warn('[SPEECH] User Agent:', navigator.userAgent);
                transcriptStatus.textContent = 'Not supported on iOS';
                addTranscriptEntry('System', 'üì± Real-time transcription is not supported on iOS devices.', 'system');
                addTranscriptEntry('System', 'üí° Transcription will still be available after the recording ends.', 'system');
                return;
            }
            
            // Check if browser supports speech recognition
            if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                console.warn('[SPEECH] Speech recognition not supported in this browser');
                console.warn('[SPEECH] Browser:', navigator.userAgent);
                transcriptStatus.textContent = 'Not supported';
                addTranscriptEntry('System', '‚ö†Ô∏è Speech recognition is not supported in this browser. Try Chrome or Edge.', 'system');
                addTranscriptEntry('System', 'üí° Note: Each participant transcribes their own audio locally', 'system');
                return;
            }
            
            const SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition;
            recognition = new SpeechRecognition();
            
            // Configure recognition
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';
            recognition.maxAlternatives = 1;
            
            // Handle results
            recognition.onresult = (event) => {
                let finalTranscript = '';
                interimTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript;
                    } else {
                        interimTranscript += transcript;
                    }
                }
                
                // Add final transcript as an entry
                if (finalTranscript) {
                    // Determine speaker based on role
                    const speaker = isInterviewer ? 'Interviewer' : 'Interviewee';
                    
                    console.log('[SPEECH RESULT] Final transcript detected');
                    console.log('[SPEECH RESULT] Speaker:', speaker);
                    console.log('[SPEECH RESULT] Text:', finalTranscript);
                    console.log('[SPEECH RESULT] Panel open:', isTranscriptOpen);
                    
                    // Try to add to UI if panel is open
                    addTranscriptEntry(speaker, finalTranscript, 'local');
                    
                    // ALWAYS send transcript to other participant (even if panel is closed)
                    if (socket && socket.connected) {
                        console.log('[TRANSCRIPT SEND] Sending to remote participant');
                        console.log('[TRANSCRIPT SEND] Role:', speaker);
                        console.log('[TRANSCRIPT SEND] Text:', finalTranscript.substring(0, 50) + '...');
                        socket.emit('transcript', {
                            roomId: roomId,
                            speaker: speaker,
                            text: finalTranscript,
                            timestamp: Date.now()
                        });
                    } else {
                        console.error('[TRANSCRIPT SEND] ERROR - Socket not connected, cannot send transcript');
                    }
                    
                    // Always log transcript for debugging
                    console.log('[LOCAL TRANSCRIPT SUMMARY]', speaker + ':', finalTranscript);
                }
                
                // Update interim display if needed
                updateInterimTranscript(interimTranscript);
            };
            
            recognition.onstart = () => {
                isTranscribing = true;
                if (transcriptStatus) {
                    transcriptStatus.textContent = 'Listening';
                }
                console.log('[SPEECH] Recognition started for', isInterviewer ? 'INTERVIEWER' : 'INTERVIEWEE');
                console.log('[SPEECH] Auto-transcription:', autoTranscriptionEnabled, 'Panel open:', isTranscriptOpen);
            };
            
            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                
                // Handle different error types
                if (event.error === 'no-speech') {
                    // ONLY restart if NOT muted
                    if (isAudioEnabled) {
                        setTimeout(() => {
                            if (isTranscriptOpen && isAudioEnabled && recognition) {
                                try {
                                    recognition.start();
                                } catch (e) {
                                    console.log('Recognition restart after no-speech failed:', e);
                                }
                            }
                        }, 1000);
                    }
                } else if (event.error === 'not-allowed') {
                    transcriptStatus.textContent = 'Permission Denied';
                    addTranscriptEntry('System', '‚ö†Ô∏è Microphone permission denied. Please allow microphone access.', 'system');
                } else if (event.error === 'network') {
                    // Network error - try to restart if conditions are met
                    transcriptStatus.textContent = 'Network Error';
                    if (isAudioEnabled && isTranscriptOpen) {
                        console.log('Network error detected, attempting to restart...');
                        setTimeout(() => {
                            if (isTranscriptOpen && isAudioEnabled) {
                                try {
                                    recognition.start();
                                    console.log('Restarted after network error');
                                } catch (e) {
                                    console.log('Failed to restart after network error:', e);
                                    transcriptStatus.textContent = 'Error - Try refreshing';
                                }
                            }
                        }, 500);
                    }
                } else if (event.error === 'aborted') {
                    // Recognition was aborted, likely due to muting
                    if (!isAudioEnabled) {
                        transcriptStatus.textContent = 'Muted';
                    } else {
                        transcriptStatus.textContent = 'Stopped';
                    }
                } else {
                    // Other errors
                    transcriptStatus.textContent = 'Error';
                    console.error('Unhandled recognition error:', event.error);
                }
            };
            
            recognition.onend = () => {
                isTranscribing = false;
                
                // Restart if microphone is enabled AND (panel is open OR auto-transcription is enabled)
                if ((isTranscriptOpen || autoTranscriptionEnabled) && isAudioEnabled) {
                    if (transcriptStatus) {
                        transcriptStatus.textContent = 'Restarting...';
                    }
                    setTimeout(() => {
                        if ((isTranscriptOpen || autoTranscriptionEnabled) && isAudioEnabled && recognition) {
                            try {
                                recognition.start();
                                console.log('[SPEECH] Recognition restarted (auto=' + autoTranscriptionEnabled + ', open=' + isTranscriptOpen + ')');
                            } catch (e) {
                                console.log('Recognition restart failed:', e);
                            }
                        }
                    }, 100);
                } else if (!isAudioEnabled) {
                    if (transcriptStatus) {
                        transcriptStatus.textContent = 'Muted';
                    }
                    console.log('[SPEECH] Not restarting recognition - microphone is muted');
                } else {
                    if (transcriptStatus) {
                        transcriptStatus.textContent = 'Stopped';
                    }
                }
            };
            
            // Start recognition
            try {
                recognition.start();
            } catch (e) {
                console.error('Failed to start recognition:', e);
            }
        }
        
        // Add transcript entry to the panel
        function addTranscriptEntry(speaker, text, type = 'local') {
            // CRITICAL FIX: Only check if panel is open, not the role
            if (!isTranscriptOpen) {
                console.log('[TRANSCRIPT LOG] Panel closed -', speaker + ':', text);
                return;
            }
            
            // Remove empty message if it exists
            const emptyMsg = transcriptContent.querySelector('.transcript-empty');
            if (emptyMsg) {
                emptyMsg.remove();
            }
            
            // Remove any existing interim transcript display
            const existingInterim = transcriptContent.querySelector('.transcript-interim');
            if (existingInterim) {
                existingInterim.remove();
            }
            
            // Create entry element
            const entry = document.createElement('div');
            entry.className = `transcript-entry ${type}`;
            
            const speakerElem = document.createElement('div');
            speakerElem.className = 'transcript-speaker';
            speakerElem.textContent = speaker;
            
            const textElem = document.createElement('div');
            textElem.className = 'transcript-text';
            textElem.textContent = text;
            
            const timestamp = document.createElement('div');
            timestamp.className = 'transcript-timestamp';
            const time = new Date();
            timestamp.textContent = time.toLocaleTimeString('en-US', { 
                hour: '2-digit', 
                minute: '2-digit', 
                second: '2-digit' 
            });
            
            entry.appendChild(speakerElem);
            entry.appendChild(textElem);
            entry.appendChild(timestamp);
            
            transcriptContent.appendChild(entry);
            
            // Auto-scroll to bottom
            transcriptContent.scrollTop = transcriptContent.scrollHeight;
            
            // Store entry for later export if needed
            transcriptEntries.push({
                speaker,
                text,
                timestamp: Date.now(),
                type
            });
        }
        
        // Update interim transcript display
        function updateInterimTranscript(text) {
            // Remove existing interim display
            let interimElem = transcriptContent.querySelector('.transcript-interim');
            
            if (text) {
                if (!interimElem) {
                    interimElem = document.createElement('div');
                    interimElem.className = 'transcript-listening';
                    transcriptContent.appendChild(interimElem);
                }
                
                interimElem.innerHTML = `
                    <div class="transcript-listening-text">
                        <span>üé§</span>
                        <span>${text}</span>
                    </div>
                `;
                
                // Auto-scroll to bottom
                transcriptContent.scrollTop = transcriptContent.scrollHeight;
            } else if (interimElem) {
                interimElem.remove();
            }
        }
        
        // Handle incoming transcripts from remote participant
        socket.on('transcript', (data) => {
            console.log('[TRANSCRIPT RECEIVED]', 'Speaker:', data.speaker, 'Text:', data.text?.substring(0, 50) + '...');
            
            // Check if this is from the other participant
            const myRole = isInterviewer ? 'Interviewer' : 'Interviewee';
            if (data.speaker !== myRole) {
                console.log('[TRANSCRIPT] Processing remote transcript from', data.speaker);
                
                // CRITICAL FIX: Add to panel for BOTH participants if their panel is open
                if (isTranscriptOpen) {
                    // Force add to transcript panel
                    const emptyMsg = transcriptContent.querySelector('.transcript-empty');
                    if (emptyMsg) {
                        emptyMsg.remove();
                    }
                    
                    const entry = document.createElement('div');
                    entry.className = 'transcript-entry remote';
                    entry.innerHTML = `
                        <div class="transcript-speaker">${data.speaker}</div>
                        <div class="transcript-text">${data.text}</div>
                        <div class="transcript-timestamp">${new Date(data.timestamp || Date.now()).toLocaleTimeString()}</div>
                    `;
                    transcriptContent.appendChild(entry);
                    transcriptContent.scrollTop = transcriptContent.scrollHeight;
                    
                    console.log('[TRANSCRIPT] Added remote transcript to panel for', myRole);
                } else {
                    console.log('[TRANSCRIPT] Panel closed, just logging:', data.speaker, data.text);
                }
            } else {
                console.log('[TRANSCRIPT] Ignoring own transcript echo');
            }
        });
        
        // Handle transcript status from remote participant
        socket.on('transcript-status', (data) => {
            if (data.participant !== (isInterviewer ? 'Interviewer' : 'Interviewee')) {
                // This is from the remote participant
                if (data.isOpen) {
                    console.log('[TRANSCRIPT STATUS] Remote participant enabled transcription');
                    if (isTranscriptOpen) {
                        addTranscriptEntry('System', `‚úÖ ${data.participant} has enabled transcription`, 'system');
                    }
                } else {
                    console.log('[TRANSCRIPT STATUS] Remote participant disabled transcription');
                    if (isTranscriptOpen) {
                        addTranscriptEntry('System', `‚ö†Ô∏è ${data.participant} has disabled transcription - you won't see their speech`, 'system');
                    }
                }
            }
        });
        
        // Stop speech recognition when call ends
        window.addEventListener('beforeunload', () => {
            if (recognition) {
                recognition.stop();
            }
        });
        
        // Also stop when ending call
        const originalEndCall = document.getElementById('endCall').onclick;
        document.getElementById('endCall').onclick = function() {
            if (recognition) {
                recognition.stop();
            }
            if (originalEndCall) originalEndCall.apply(this, arguments);
        };
    </script>
</body>
</html>