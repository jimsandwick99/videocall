#!/usr/bin/env node

// Step 2: Test transcription with the exact format Twilio uses
const fs = require('fs-extra');
const path = require('path');
const { exec } = require('child_process');
const util = require('util');
const execPromise = util.promisify(exec);
const OpenAI = require('openai');
require('dotenv').config();

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
});

async function testTwilioFormat() {
    console.log('\nüß™ STEP 2: Testing Twilio Audio Format (.mka)\n');
    console.log('=' .repeat(60));
    
    try {
        const testDir = path.join(__dirname, 'test-audio');
        await fs.ensureDir(testDir);
        
        // 1. Create test audio that simulates Twilio format
        console.log('\n1Ô∏è‚É£  Creating test audio in Twilio format (.mka with Opus codec)...');
        
        // First create a base audio file
        const testText = "This is the interviewer speaking. Can you tell me about your experience?";
        const aiffFile = path.join(testDir, 'interviewer.aiff');
        
        console.log('   Generating interviewer audio...');
        await execPromise(`say -o "${aiffFile}" "${testText}"`);
        
        // Convert to MKA format (what Twilio produces)
        const mkaFile = path.join(testDir, 'interviewer_audio_test.mka');
        console.log('   Converting to .mka (Opus codec, like Twilio)...');
        await execPromise(`ffmpeg -i "${aiffFile}" -c:a libopus -b:a 48k "${mkaFile}" -y`);
        
        const stats = await fs.stat(mkaFile);
        console.log(`   ‚úÖ Created MKA file: ${mkaFile}`);
        console.log(`   File size: ${Math.round(stats.size / 1024)}KB`);
        
        // 2. Test if OpenAI can handle MKA directly
        console.log('\n2Ô∏è‚É£  Testing if OpenAI accepts .mka files directly...');
        
        const mkaBuffer = await fs.readFile(mkaFile);
        
        // Try different MIME types
        const mimeTypes = [
            'audio/x-matroska',
            'audio/webm',
            'video/x-matroska',
            'application/octet-stream'
        ];
        
        let directTranscriptionWorks = false;
        
        for (const mimeType of mimeTypes) {
            console.log(`   Trying MIME type: ${mimeType}`);
            try {
                const file = new File([mkaBuffer], 'test.mka', { type: mimeType });
                const transcription = await openai.audio.transcriptions.create({
                    file: file,
                    model: 'whisper-1',
                    response_format: 'text'
                });
                console.log(`   ‚úÖ SUCCESS with ${mimeType}!`);
                console.log(`   Transcription: ${transcription}`);
                directTranscriptionWorks = true;
                break;
            } catch (error) {
                console.log(`   ‚ùå Failed: ${error.message.substring(0, 50)}...`);
            }
        }
        
        if (!directTranscriptionWorks) {
            console.log('\n3Ô∏è‚É£  OpenAI doesn\'t accept .mka directly. Testing conversion pipeline...');
            
            // Convert MKA to formats OpenAI accepts
            const formats = [
                { ext: 'mp3', codec: 'libmp3lame', mime: 'audio/mpeg' },
                { ext: 'm4a', codec: 'aac', mime: 'audio/mp4' },
                { ext: 'wav', codec: 'pcm_s16le', mime: 'audio/wav' },
                { ext: 'webm', codec: 'libopus', mime: 'audio/webm' }
            ];
            
            for (const format of formats) {
                console.log(`\n   Testing ${format.ext.toUpperCase()} format...`);
                const convertedFile = path.join(testDir, `converted.${format.ext}`);
                
                try {
                    // Convert MKA to target format
                    await execPromise(`ffmpeg -i "${mkaFile}" -c:a ${format.codec} "${convertedFile}" -y`);
                    const convertedStats = await fs.stat(convertedFile);
                    console.log(`   Converted size: ${Math.round(convertedStats.size / 1024)}KB`);
                    
                    // Try transcription
                    const buffer = await fs.readFile(convertedFile);
                    const file = new File([buffer], `test.${format.ext}`, { type: format.mime });
                    
                    const transcription = await openai.audio.transcriptions.create({
                        file: file,
                        model: 'whisper-1',
                        response_format: 'text'
                    });
                    
                    console.log(`   ‚úÖ ${format.ext.toUpperCase()} transcription works!`);
                    console.log(`   Result: ${transcription.substring(0, 60)}...`);
                    
                } catch (error) {
                    console.log(`   ‚ùå ${format.ext.toUpperCase()} failed: ${error.message.substring(0, 40)}...`);
                }
            }
        }
        
        // 4. Test the actual transcribe-twilio.js function
        console.log('\n4Ô∏è‚É£  Testing our transcribe-twilio.js with simulated Twilio recording...');
        
        // Create a fake Twilio recording structure
        const fakeRoomId = 'test-room-' + Date.now();
        const twilioDir = path.join(__dirname, 'recordings', fakeRoomId, 'twilio');
        await fs.ensureDir(twilioDir);
        
        // Copy our test MKA file to the Twilio directory
        await fs.copy(mkaFile, path.join(twilioDir, 'interviewer_audio_test.mka'));
        
        // Also create an interviewee file
        const intervieweeText = "Sure, I have five years of experience in software development.";
        const intervieweeAiff = path.join(testDir, 'interviewee.aiff');
        const intervieweeMka = path.join(twilioDir, 'interviewee_audio_test.mka');
        
        await execPromise(`say -v Samantha -o "${intervieweeAiff}" "${intervieweeText}"`);
        await execPromise(`ffmpeg -i "${intervieweeAiff}" -c:a libopus -b:a 48k "${intervieweeMka}" -y`);
        
        console.log(`   Created fake Twilio recording structure at: ${twilioDir}`);
        
        // Run the transcription
        const transcribeTwilioRecording = require('./transcribe-twilio');
        
        console.log('   Running transcription...');
        try {
            const result = await transcribeTwilioRecording(fakeRoomId);
            console.log('   ‚úÖ Transcription completed!');
            console.log(`   Transcript saved to: ${result.readablePath}`);
            
            // Read and display the transcript
            const transcript = await fs.readFile(result.readablePath, 'utf-8');
            console.log('\n   Generated Transcript Preview:');
            console.log('   ' + '-'.repeat(40));
            console.log(transcript.substring(0, 500));
            console.log('   ' + '-'.repeat(40));
            
        } catch (error) {
            console.log('   ‚ùå Transcription failed:', error.message);
        }
        
        console.log('\n' + '=' .repeat(60));
        console.log('\nüìä TEST RESULTS:');
        console.log('‚úÖ MKA files can be created (Twilio format)');
        console.log('‚úÖ MKA can be converted to MP3/M4A/WAV for transcription');
        console.log('‚úÖ Transcription pipeline works with converted files');
        console.log('‚úÖ Full transcribe-twilio.js function is operational');
        
        return true;
        
    } catch (error) {
        console.error('\n‚ùå Test failed:', error.message);
        console.error(error.stack);
        return false;
    }
}

// Run the test
testTwilioFormat();